@inproceedings{ahmadilivani_special_2023,
  title = {Special {{Session}}: {{Approximation}} and {{Fault Resiliency}} of {{DNN Accelerators}}},
  booktitle = {2023 {{IEEE}} 41st {{VLSI Test Symposium}} ({{VTS}})},
  author = {Ahmadilivani, Mohammad Hasan and Barbareschi, Mario and Barone, Salvatore and Bosio, Alberto and Daneshtalab, Masoud and Della Torca, Salvatore and Gavarini, Gabriele and Jenihhin, Maksim and Raik, Jaan and Ruospo, Annachiara},
  year = {2023},
  doi = {10.1109/VTS56346.2023.10140043}
}

@article{barbareschi_advancing_2021,
  title = {Advancing Synthesis of Decision Tree-Based Multiple Classifier Systems: An Approximate Computing Case Study},
  author = {Barbareschi, Mario and Barone, Salvatore and Mazzocca, Nicola},
  year = {2021},
  journal = {Knowledge and Information Systems},
  doi = {10.1007/s10115-021-01565-5},
  abstract = {So far, multiple classifier systems have been increasingly designed to take advantage of hardware features, such as high parallelism and computational power. Indeed, compared to software implementations, hardware accelerators guarantee higher throughput and lower latency. Although the combination of multiple classifiers leads to high classification accuracy, the required area overhead makes the design of a hardware accelerator unfeasible, hindering the adoption of commercial configurable devices. For this reason, in this paper, we exploit approximate computing design paradigm to trade hardware area overhead off for classification accuracy. In particular, starting from trained DT models and employing precision-scaling technique, we explore approximate decision tree variants by means of multiple objective optimization problem, demonstrating a significant performance improvement targeting field-programmable gate array devices.}
}

@inproceedings{barbareschi_automatic_2023,
  title = {Automatic {{Test Generation}} to {{Improve Scrum}} for {{Safety Agile Methodology}}},
  booktitle = {Proceedings of the 18th {{International Conference}} on {{Availability}}, {{Reliability}} and {{Security}}},
  author = {Barbareschi, Mario and Barone, Salvatore and Casola, Valentina and Della Torca, Salvatore and Lombardi, Daniele},
  year = {2023},
  doi = {10.1145/3600160.3605061}
}

@incollection{barbareschi_automatic_2024,
  title = {Automatic {{Approximation}} of {{Computer Systems Through Multi-objective Optimization}}},
  booktitle = {Design and {{Applications}} of {{Emerging Computer Systems}}},
  author = {Barbareschi, Mario and Barone, Salvatore and Bosio, Alberto and Traiola, Marcello},
  editor = {Liu, Weiqiang and Han, Jie and Lombardi, Fabrizio},
  year = {2024},
  doi = {10.1007/978-3-031-42478-6\_15},
  abstract = {In this chapter, we address the automatic approximation of computer systems through multi-objective optimization. Firstly, we present our automatic design methodology, i.e., how we model the approximate design space to be automatically explored. The exploration is achieved through multi-objective optimization to find good trade-offs between the system efficiency and accuracy. Then, we show how the methodology is applied to the systematic and application-independent design of generic combinational logic circuits, based on non-trivial local rewriting of and-inverter graphs (AIGs). Finally, to push forward the approximation limits, we showcase the design of approximate hardware accelerators for image processing and for common machine-learning-based classification models.}
}

@article{barbareschi_catalog-based_2022,
  title = {A {{Catalog-based AIG-Rewriting Approach}} to the {{Design}} of {{Approximate Components}}},
  author = {Barbareschi, Mario and Barone, Salvatore and Mazzocca, Nicola and Moriconi, Alberto},
  year = {2022},
  journal = {IEEE Transactions on Emerging Topics in Computing},
  doi = {10.1109/TETC.2022.3170502},
  abstract = {As computational demand and energy efficiency of computer systems are becoming increasingly relevant requirements, traditional design paradigms are bound to become no longer appropriate, as they cannot guarantee significant improvements. The approximate-computing design paradigm has been introduced as a potential candidate to achieve better performances, by relaxing non-critical functional specifications. Anyway, several challenges need to be addressed in order to exploit its potential. In this paper, we propose a systematic and application-independent approximate design approach suitable to combinational logic circuits.  Our approach is based on non-trivial local rewriting of and-inverter graphs (AIG), reducing the number of AIG-nodes and possibly resulting in lower hardware resources requirements.  We adopt multi-objective optimization to carefully introduce approximation while aiming at optimal trade-offs between error and hardware-requirements.  We evaluate our approach using different benchmarks, and, in order to measure actual gains, we perform actual synthesis of Pareto-optimal approximate configurations.  Experimental results show that the proposed approach allows achieving significant savings, since resulting approximate circuits exhibit lower requirements and restrained error w.r.t. their exact couterparts.}
}

@inproceedings{barbareschi_comprehensive_2024,
  title = {A Comprehensive Evaluation of Interrupt Measurement Techniques for Predictability in Safety-Critical Systems},
  booktitle = {Proceedings of the 19th {{International Conference}} on {{Availability}}, {{Reliability}} and {{Security}} ({{ARES}} 2024) ({{In}} Press)},
  author = {Barbareschi, Mario and Barone, Salvatore and Casola, Valentina and Lombardi, Daniele},
  year = {2024},
  doi = {10.1145/3664476.3670451},
  abstract = {In the last few decades, the increasing adoption of computer systems for monitoring and control applications has fostered growing attention to real-time behavior, i.e., the property that ensures predictable reaction times to external events.  In this perspective, performance of the interrupt management mechanisms are among the most relevant aspects to be considered. Therefore, the service-latency of interrupts is one of the metrics considered while assessing the predictability of such systems. To this purpose, there are different techniques to estimate it, including the use of on-board timers, oscilloscopes and logic analyzers, or even real-time tracers.  Each of these techniques, however, is affected by some degrees of inaccuracy, and choosing one over the other have pros and cons. In this paper, we review methodologies for measuring interrupt-latency from the scientific literature and, for the first time, we define an analytical model that we exploit to figure out measurement errors committed. Finally, we prove the effectiveness of the model relying on measurements taken from Xilinx MPSoC devices and  present a case study whose purpose is to validate the proposed model.}
}

@incollection{barbareschi_design_2022,
  title = {Design {{Space Exploration Tools}}},
  booktitle = {Approximate {{Computing Techniques}}: {{From Component-}} to {{Application-Level}}},
  author = {Barbareschi, Mario and Barone, Salvatore and Mazzocca, Nicola and Moriconi, Alberto},
  editor = {Bosio, Alberto and M{\'e}nard, Daniel and Sentieys, Olivier},
  year = {2022},
  doi = {10.1007/978-3-030-94705-7_8},
  abstract = {The Approximate Computing design paradigm has repeatedly shown to be well suited to the needs of modern applications, especially those that interact with the physical world and process large amounts of data. By leveraging the presence of error-tolerant data and algorithms and the perceptual limitations of end-users, it allows to selectively relax the correctness requirements, achieving great performance enhancement and admitting a negligible output quality loss. Unfortunately, applying Approximate Computing to its full potential requires addressing several challenges: there is neither a generic methodology for identifying approximable code or circuit parts nor an approach for selecting the most suitable approximate techniques to apply. However, several tools have been proposed that seek to automate or at least guide part of the approximation process. In this chapter, we first discuss the state of the art for automatic tools for Approximate Computing, targeting digital circuits and software applications. We then introduce {$\mathbb{I}$}DE{$\mathbb{A}\$\$\backslash$}mathbb \{I\}{\textbackslash}text\{ \{DE\}\}{\textbackslash}mathbb \{A\}\$\$, an extendible tool suite that allows to describe Approximate Computing techniques, apply them to C/C++ code, and explore the design space of the obtained approximate variants to find an estimate of the Pareto front.}
}

@inproceedings{barbareschi_efficient_2019,
  title = {Efficient {{Reed-Muller Implementation}} for {{Fuzzy Extractor Schemes}}},
  booktitle = {2019 14th {{International Conference}} on {{Design}} \& {{Technology}} of {{Integrated Systems In Nanoscale Era}} ({{DTIS}})},
  author = {Barbareschi, Mario and Barone, Salvatore and Mazzeo, Antonino and Mazzocca, Nicola},
  year = {2019},
  doi = {10.1109/DTIS.2019.8735029},
  abstract = {Nowadays, physical tampering and counterfeiting of electronic devices are still an important security problem and have a great impact on large-scale and distributed applications, such as Internet-of-Things. Physical Unclonable Functions (PUFs) have the potential to be a fundamental means to guarantee intrinsic hardware security, since they promise immunity against most of known attack models. However, inner nature of PUF circuits hinders a wider adoption since responses turn out to be noisy and not stable during time. To overcome this issue, most of PUF implementations require a fuzzy extraction scheme, able to recover responses stability by exploiting error correction codes (ECCs). In this paper, we propose a Reed-Muller (RM) ECC design, meant to be embedded into a fuzzy extractor, that can be efficiently configured in terms of area/delay constraints in order to get reliable responses from PUFs. We provide implementation details and experimental evidences of area/delay efficiency through syntheses on medium-range FPGA device.}
}

@inproceedings{barbareschi_exploiting_2024,
  title = {Exploiting {{Functional Approximation}} on {{Decision-Tree}} Based {{Multiple Classifier Systems}}},
  booktitle = {Proceedingsof the {{IFIP}}/{{IEEE International Conference}} on {{Very Large Scale Integration}}},
  author = {Barbareschi, Mario and Barone, Salvatore and Emmanuele, Antonio and Mazzocca, Nicola},
  year = {2024},
  abstract = {Multiple Classifier Systems (MCSs) have been increasingly designed to take advantage of hardware features, such as high parallelism and computational power, to guarantee higher throughput and lower latency.  Although the combination of multiple classifiers leads to high classification accuracy, the required area overhead makes the design of a hardware accelerator unfeasible, hindering the adoption of commercial configurable devices. For this reason, in this paper, we exploit the Approximate Computing (AxC) design paradigm to automatically generate approximated hardware implementations of MCSs by trading hardware area overhead off for classification accuracy. In particular, we propose an algorithm that identifies the resiliency source of the model and uses it to introduce approximation with minimum accuracy loss. In order to prove the effectiveness of our solution, we performed numerous experiments on models of various sizes trained on different datasets. The results show that with negligible accuracy loss it is possible to significantly reduce the hardware requirements of a classifier.}
}

@article{barbareschi_fpga_2024,
  title = {{{FPGA Approximate Logic Synthesis}} through {{Catalog-Based AIG-Rewriting Technique}}},
  author = {Barbareschi, Mario and Barone, Salvatore and Mazzocca, Nicola and Moriconi, Alberto},
  year = {2024},
  journal = {Journal of Systems Architecture},
  volume = {150},
  doi = {10.1016/j.sysarc.2024.103112},
  abstract = {Due to their  run-time reconfigurability, short time-to-market, and lower prototype costs, FPGAs have become increasingly popular since their introduction. They found use in a wide variety of applications, including  high-performance computing. However, when compared to ASICs, FPGAs offer lower performance, and they are power-hungry devices with low energy-efficiency.  The emergence of Approximate Computing (AxC) represents a significant advancement in terms of enabling technology when applied to FPGA-based computing platforms. It has been effectively exploited in several application fields, achieving significant savings in energy and latency through a selective degradation  of the output quality. Nevertheless, a generalized and systematic methodology for FPGA-based circuit design is still lacking. Indeed, most of the methods target ASIC-based systems, and, consequently, they offer minimal advantages or even an increase in resources when synthesized for FPGAs due to the architectural differences between the technologies. In this paper, we attempt to address this shortcoming by introducing our method for designing combinational logic circuits. It is based on and-inverter graph rewriting and multi-objective optimization, aiming for optimal trade-offs between quality of results and hardware overhead. Extensive experimental campaigns empirically prove that both generic logic and arithmetic circuits benefit from this approach.}
}

@article{barbareschi_genetic-algorithm-based_2022,
  title = {A {{Genetic-algorithm-based Approach}} to the {{Design}} of {{DCT Hardware Accelerators}}},
  author = {Barbareschi, Mario and Barone, Salvatore and Bosio, Alberto and Han, Jie and Traiola, Marcello},
  year = {2022},
  journal = {ACM Journal on Emerging Technologies in Computing Systems},
  volume = {18},
  number = {3},
  doi = {10.1145/3501772},
  abstract = {As modern applications demand an unprecedented level of computational resources, traditional computing system design paradigms are no longer adequate to guarantee significant performance enhancement at an affordable cost. Approximate Computing (AxC) has been introduced as a potential candidate to achieve better computational performances by relaxing non-critical functional system specifications. In this article, we propose a systematic and high-abstraction-level approach allowing the automatic generation of near Pareto-optimal approximate configurations for a Discrete Cosine Transform (DCT) hardware accelerator. We obtain the approximate variants by using approximate operations, having configurable approximation degree, rather than full-precise ones. We use a genetic searching algorithm to find the appropriate tuning of the approximation degree, leading to optimal tradeoffs between accuracy and gains. Finally, to evaluate the actual HW gains, we synthesize non-dominated approximate DCT variants for two different target technologies, namely, Field Programmable Gate Arrays (FPGAs) and Application Specific Integrated Circuits (ASICs). Experimental results show that the proposed approach allows performing a meaningful exploration of the design space to find the best tradeoffs in a reasonable time. Indeed, compared to the state-of-the-art work on approximate DCT, the proposed approach allows an 18\% average energy improvement while providing at the same time image quality improvement.}
}

@article{barbareschi_investigating_2024,
  title = {Investigating the {{Resilience Source}} of {{Classification Systems}} for {{Approximate Computing Techniques}}},
  author = {Barbareschi, Mario and Barone, Salvatore},
  year = {2024},
  journal = {IEEE Transactions on Emerging Topics in Computing},
  doi = {10.1109/TETC.2024.3403757},
  abstract = {During the last decade, classification systems (CSs) received significant research attention, with new learning algorithms achieving high accuracy in various applications. However, their resource-intensive nature, in terms of hardware and computation time, poses new design challenges.  CSs exhibit inherent error resilience, due to redundancy of training sets, and self-healing properties, making them suitable for Approximate Computing (AxC). AxC enables efficient computation by using reduced precision or approximate values, leading to energy, time, and silicon area savings. Exploiting AxC involves estimating the introduced error for each approximate variant found during a Design-Space Exploration (DSE). This estimation has to be both rapid and meaningful, considering a substantial number of test samples, which are utterly conflicting demands. In this paper, we investigate on sources of error resiliency of CSs, and we propose a technique to haste the DSE that reduces the computational time for error estimation by systematically reducing the test set. In particular, we cherry-pick samples that are likely to be more sensitive to approximation and perform accuracy-loss estimation just by exploiting such a sample subset. In order to demonstrate its efficacy, we integrate our technique into two different approaches for generating approximate CSs, showing an average speed-up up to approx18.}
}

@inproceedings{barbareschi_memory_2022,
  title = {A {{Memory Protection Strategy}} for {{Resource Constrained Devices}} in {{Safety Critical Applications}}},
  booktitle = {2022 6th {{International Conference}} on {{System Reliability}} and {{Safety}} ({{ICSRS}})},
  author = {Barbareschi, Mario and Barone, Salvatore and Casola, Valentina and Montone, Pasquale and Moriconi, Alberto},
  year = {2022},
  doi = {10.1109/ICSRS56243.2022.10067350},
  abstract = {In modern safety-related applications, software has achieved an increasingly critical role. Their safety-critical nature, however, requires special attention: industry-specific functionalsafety standards guide designers, developers, integrators, and testers during all phases of the software life-cycle and the final artifacts undergo a rigorous certification process.}
}

@article{barbareschi_scrum_2022,
  title = {Scrum for Safety: An Agile Methodology for Safety-Critical Software Systems},
  author = {Barbareschi, Mario and Barone, Salvatore and Carbone, Riccardo and Casola, Valentina},
  year = {2022},
  journal = {Software Quality Journal},
  volume = {30},
  number = {4},
  doi = {10.1007/s11219-022-09593-2},
  abstract = {In the last years, agile methodologies are gaining substantial momentum, becoming increasingly popular in a broad plethora of industrial contexts. Unfortunately, many obstacles have been met while pursuing adoption in secure and safe systems, where different standards and operational constraints apply. In this paper, we propose a novel agile methodology for the development and innovation of safety-critical systems. In particular, we developed an extension of the well-known Scrum methodology and discussed the complete workflow. We finally validated the applicability of the proposed methodology over a real case study from the railway domain.}
}

@inproceedings{barone_ineffectiveness_2024,
  title = {Ineffectiveness of {{Digital Transformations}} for {{Detecting Adversarial Attacks}} against {{Quantized}} and {{Approximate CNNs}}},
  booktitle = {Proceedings of the 2024 {{IEEE International Conference}} on {{Cyber Security}} and {{Resilience}} ({{In}} Press)},
  author = {Barone, Salvatore and Casola, Valentina and Della Torca, Salvatore},
  year = {2024},
  abstract = {Convolutional Neural Networks (CNNs) have achieved superhuman performance in computer vision tasks. However, these networks are becoming both increasingly complex and resource-intensive, and are susceptible to adversarial attacks. On one hand, to counter complexity and resource-related limitations, various techniques such as Quantization and Approximate Computing (AxC) have been proposed to reduce the complexity and power consumption of CNNs, respectively.  On the other hand, various techniques have been proposed to craft more precise and stronger adversarial attacks, as well as new methodologies to defend against them. Nevertheless, the relationship between the efficiency and security of CNNs is not adequately addressed. Therefore, this article examines the potential for detecting adversarial attacks against CNNs through image transformation, in the context of quantized and approximate neural networks.  The experimental results indicate that image-transformation techniques are not effective in detecting adversarial samples against quantized and approximated CNNs, despite their success in detecting such samples against floating-point CNNs.}
}

@article{barone_multi-objective_2021,
  title = {Multi-{{Objective Application-Driven Approximate Design Method}}},
  author = {Barone, Salvatore and Traiola, Marcello and Barbareschi, Mario and Bosio, Alberto},
  year = {2021},
  journal = {IEEE Access},
  volume = {9},
  doi = {10.1109/ACCESS.2021.3087858},
  abstract = {Approximate Computing (AxC) paradigm aims at designing computing systems that can satisfy the rising performance demands and improve the energy efficiency. AxC exploits the gap between the level of accuracy required by the users, and the actual precision provided by the computing system, for achieving diverse optimizations. Various AxC techniques have been proposed so far in the literature at different abstraction levels from hardware to software. These techniques have been successfully utilized and combined to realize approximate implementations of applications in various domains (e.g. data analytic, scientific computing, multimedia and signal processing, and machine learning). Unfortunately, state-of-the-art approximation methodologies focus on a single abstraction level, such as combining elementary components (e.g., arithmetic operations) which are firstly approximated using component-level metrics and then combined to provide a good trade-off between efficiency and accuracy at the application level. This hinders the possibility for designers to explore different approximation opportunities, optimized for different applications and implementation targets. Therefore, we designed and implemented E- \${\textbackslash}mathbb IDEA\$ , an automatic framework that provides an application-driven approximation approach to find the best approximate versions of a given application targeting different implementations (i.e., hardware and software). E- \${\textbackslash}mathbb IDEA\$ compounds 1) a source-to-source manipulation tool and 2) an evolutionary search engine to automatically realize approximate application variants and perform a Design-Space Exploration (DSE). The latter results in a set of non-dominate approximate solutions in terms of trade-off between accuracy and efficiency. Experimental results validate the effectiveness and the flexibility of the approach in generating optimized approximate implementations of different applications, by using different approximation techniques and different accuracy/error metrics and for different implementation targets.}
}

@inproceedings{barone_timing_2023,
  title = {Timing {{Behavior Characterization}} of {{Critical Real-Time Systems}} through {{Hybrid Timing Analysis}}},
  booktitle = {2023 7th {{International Conference}} on {{System Reliability}} and {{Safety}} ({{ICSRS}})},
  author = {Barone, Salvatore and Casola, Valentina and Torca, Salvatore Della and Lombardi, Daniele},
  year = {2023},
  doi = {10.1109/ICSRS59833.2023.10381272},
  abstract = {The spread of computing-systems, especially the real-time embedded ones, is rapidly growing in the last years, since they find usage in numerous fields of application, including, but not limited to, industry process, critical infrastructures, transportation systems, as so forth. Indeed, in these fields, precise time-constraints hold; hence, tasks need to be correct from both the functional and temporal perspectives. As for the latter, timing behavior has to be characterized, that is usually done by exploiting either static or dynamic analysis techniques, which leverage estimations based on either a model or the actual system. In this paper, we foster an automated hybrid approach that allows characterizing the timing behavior of systems while introducing any alteration, i.e., relying on instruction-level tracing rather than code instrumentation for profiling purposes. Our approach is sensitive to the execution-context, -- e.g., cache misses -- and it allows re-using results from the development processes -- e.g., unit tests. We considered a complex real-time application from the railway domain as a case study to evaluate our approach, empirically proving that it can provide a faithful characterization of systems in terms of worst-case execution time.}
}

@inproceedings{carbone_scrum_2021,
  title = {Scrum for {{Safety}}: {{Agile Development}} in {{Safety-Critical Software Systems}}},
  booktitle = {Quality of {{Information}} and {{Communications Technology}}},
  author = {Carbone, Riccardo and Barone, Salvatore and Barbareschi, Mario and Casola, Valentina},
  editor = {Paiva, Ana C. R. and Cavalli, Ana Rosa and Ventura Martins, Paula and {P{\'e}rez-Castillo}, Ricardo},
  year = {2021},
  doi = {10.1007/978-3-030-85347-1_10},
  abstract = {The adoption of agile methodologies in all domains of software development is a desired goal. Unfortunately, many obstacles have been meet in the past for a full adoption in secure and safe systems, where different standards and operational constraints apply. In this paper we propose a novel agile methodology to be applied in the development of safety critical systems. In particular, we developed an extension of the well-known Scrum methodology and discussed the complete workflow. We finally validated the applicability of the methodology over a real case study from the railway domain.}
}

@inproceedings{paiva_enforcing_2021,
  title = {Enforcing {{Mutual Authentication}} and {{Confidentiality}} in {{Wireless Sensor Networks Using Physically Unclonable Functions}}: {{A Case Study}}},
  booktitle = {Quality of {{Information}} and {{Communications Technology}}},
  author = {Barbareschi, Mario and Barone, Salvatore and Fezza, Alfonso and La Montagna, Erasmo},
  editor = {Paiva, Ana C. R. and Cavalli, Ana Rosa and Ventura Martins, Paula and {P{\'e}rez-Castillo}, Ricardo},
  year = {2021},
  volume = {1439},
  doi = {10.1007/978-3-030-85347-1_22},
  abstract = {The technological progress we witnessed in recent years has led to a pervasive usage of smart and embedded devices in many application domains. The monitoring of Power Delivery Networks (PDNs) is an example: the use of interconnected sensors makes it possible to detect faults and to dynamically adapt the network topology to isolate and compensate for them. In this paper we discuss how Fault-Detection, Isolation and Service Recovery (FDISR) for PDNs can be modeled according to the fog-computing paradigm, which distributes part of the computation among edge nodes and the cloud. In particular, we consider an FDISR application on Medium-Voltage PDNs (MV-PDNs) based on a Wireless Sensor Network (WSN) whose nodes make use of the Long Range (LoRa) technology to communicate with each other. Security concerns and the attack model of such application are discussed, then the use of a communication protocol based on the Physically Unclonable Functions (PUFs) mechanism is proposed to achieve both mutual authentication and confidentiality. Finally, an implementation of the proposal is presented and evaluated w.r.t. security concerns and communication overhead.}
}

@inproceedings{piri_input-aware_2023,
  title = {Input-Aware Accuracy Characterization for Approximate Circuits},
  booktitle = {2023 53rd {{Annual IEEE}}/{{IFIP International Conference}} on {{Dependable Systems}} and {{Networks Workshops}} ({{DSN-W}})},
  author = {Piri, Ali and Pappalardo, Salvatore and Barone, Salvatore and Barbareschi, Mario and Deveautour, Bastien and Traiola, Marcello and O'Connor, Ian and Bosio, Alberto},
  year = {2023},
  doi = {10.1109/DSN-W58399.2023.00050},
  abstract = {It has been a while since Approximate Computing (AxC) is applied systematically at various abstraction levels to increase the efficiency of several applications such as image processing and machine learning. Despite its benefit, AxC is still agnostic concerning the specific workload (i.e., input data to be processed) of a given application. For instance, in signal processing applications (such as a filter), some inputs are constants (filter coefficients). Meaning that a further level of approximation can be introduced by considering the specific input distribution. This approach has been referred to as ``input-aware approximation''. In this paper, we explore how the input-aware approximate design approach can become part of a systematic, generic, and automatic design flow by knowing the data distribution. In particular, we show how input distribution can affect the error characteristics of an approximate arithmetic circuit and also the advantage of considering the data distribution by designing an input-aware approximate multiplier specifically intended for a high-pass FIR filter, where the coefficients are constant. Experimental results show that we can significantly reduce power consumption while keeping an error rate lower than state-of-the-art approximate multipliers.}
}
